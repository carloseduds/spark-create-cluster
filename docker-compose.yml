version: '3.8'
name: cluster-spark

services:
  spark-master:
    container_name: spark-master
    build: ./dockerfiles/pyspark
    image: spark-image
    entrypoint: ['./entrypoint.sh', 'master']
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:8080"]
      interval: 5s
      timeout: 3s
      retries: 3
    volumes:
      - ./datasets:/opt/spark/dados
      - ./projetos:/opt/spark/jobs
      - spark-logs:/opt/spark/spark-events
    env_file:
      - ./dockerfiles/pyspark/.env.spark
    ports:
      - '9090:8080'
      - '7077:7077'
    networks:
      - spark-network

  spark-history:
    container_name: spark-history
    image: spark-image
    entrypoint: ['./entrypoint.sh', 'history']
    depends_on:
      - spark-master
    env_file:
      - ./dockerfiles/pyspark/.env.spark
    volumes:
      - spark-logs:/opt/spark/spark-events
    ports:
      - '18080:18080'
    restart: always
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:18080"]
      interval: 5s
      timeout: 3s
      retries: 3
    networks:
      - spark-network

  spark-worker:
    image: spark-image
    entrypoint: ['./entrypoint.sh', 'worker']
    depends_on:
      - spark-master
    env_file:
      - ./dockerfiles/pyspark/.env.spark
    volumes:
      - ./datasets:/opt/spark/dados
      - ./projetos:/opt/spark/jobs
      - spark-logs:/opt/spark/spark-events
    deploy:
      replicas: 3
    restart: always
    healthcheck:
      test: ["CMD", "curl", "-f", "http://spark-master:8080"]
      interval: 5s
      timeout: 3s
      retries: 3
    networks:
      - spark-network

  jupyter-lab:
    build: ./dockerfiles/jupyterlab
    image: jupyter-image
    depends_on:
      - spark-history
      - spark-worker
    ports:
      - "8888:8888"
      - "4040:4040"
    volumes:
      - spark-logs:/opt/spark/spark-events
      - ./projetos:/notebook/
      - ./datasets:/opt/spark/dados
    networks:
      - spark-network
    environment:
      - PYSPARK_PYTHON=python3.11
      - PYSPARK_DRIVER_PYTHON=jupyter
      - PYSPARK_SUBMIT_ARGS=--master spark://spark-master:7077 pyspark-shell

volumes:
  spark-logs:
    name: spark-cluster-logs

networks:
  spark-network:
    driver: bridge
